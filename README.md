## Arabic Image Contextualization for the Visually Impaired
<div>
<img src="https://previews.123rf.com/images/asafeliason/asafeliason1402/asafeliason140200123/25975117-arabic-alphabet-texture-background-high-resolution.jpg">    
</div>
<div>   

<br> </br> 
<img src="https://iq.opengenus.org/content/images/2020/06/Machine-Caption.png" width="550/">    
</div>
<img src="https://user-images.githubusercontent.com/9033365/50055400-181f5580-0157-11e9-8a00-1d7af672b49f.png" width="550/">    
</div>

<div style="text-align: left; background-color:#4e4e4e; font-family: Trebuchet MS; color:white; padding: 12px; line-height:1.25;border-radius:1px; margin-bottom: 0em; text-align: center; font-size: 12px;border-style: solid;border-color: dark green;"><p><b><a href="https://www.mentalfloss.com/article/535618/super-ekg-could-diagnose-heart-disease-90-seconds" target=""></a></b></p></div>


# **Introduction** <a class="anchor" id="0"></a>
"An Image Caption Generator is a deep learning application that generates captions and descriptions for images. The model is trained by passing an image to it and generating a corresponding caption or description. This field of research is challenging because it requires the model to understand and interpret the image content and convert it into natural language. This process involves utilizing methods from computer vision and natural language processing. The compositionality and nature of both language and visual information play a crucial role in training the model. The model must be trained on the co-occurrence of objects in the dataset context and must be able to generalize. Unlike the human brain, computers struggle to understand image content, and thus, models must be built to facilitate this process. The power of deep learning methods has enabled state-of-the-art results in image caption generation, allowing the creation of a single model that can predict a caption and generate a photo. Text preprocessing is a crucial step when dealing with natural language data, and it requires converting the text data into a format that machines can understand. This process is language-specific, and each language requires a specific approach." [[Source](https://www.analyticsvidhya.com/blog/2021/12/step-by-step-guide-to-build-image-caption-generator-using-deep-learning/)]

<blockquote style="margin-right:auto; margin-left:auto; color:white; background-color:#4e4e4e; padding: 1em; margin:24px;">

<font color="white" size=+1.0><b>Objectives</b></font>  
        This notebook has two main objectives:

<ul>
<li> Image Captioning: Generating natural language captions that describe the content of an image in a concise and informative way.
<li> Object Recognition: Identifying the objects and entities present in the image and providing additional information about them, such as their names, sizes, colors, and positions.
<li> Scene Description: Providing a detailed description of the scene depicted in the image, including its context, spatial layout, and relationships between objects.
<li> Navigation Assistance: Providing guidance to visually impaired individuals to help them navigate through the environment depicted in the image.

</ul>        
</blockquote>
